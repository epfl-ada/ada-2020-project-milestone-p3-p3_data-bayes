{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1. Data reading and preprocessing\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.1 imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /home/cormak/.local/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/cormak/.local/lib/python3.8/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.54.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (50.3.2)\n",
      "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.10)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/home/cormak/.local/lib/python3.8/site-packages/en_core_web_sm -->\n",
      "/home/cormak/.local/lib/python3.8/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Dataset already exists at /home/cormak/.convokit/downloads/diplomacy-corpus\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already up-to-date: scikit-learn==0.19.2 in /home/cormak/.local/lib/python3.8/site-packages (0.19.2)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import convokit\n",
    "from convokit.politenessStrategies.politenessStrategies import PolitenessStrategies\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "!python -m spacy download en\n",
    "from convokit import Corpus, download\n",
    "import pickle\n",
    "import sklearn\n",
    "#from convokit.classifier.classifier import Classifier\n",
    "from convokit import TextParser\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "from spacy.lang.en import English\n",
    "deception = Corpus(filename=download(\"diplomacy-corpus\"))\n",
    "!pip3 install -U scikit-learn==0.19.2\n",
    "import politeness\n",
    "import joblib"
   ]
  },
  {
   "source": [
    "## 1.2 politeness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* I decided to take the annotated wiki corpus to train our politeness classifier as I could notfind a working pre trained model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset already exists at /home/cormak/.convokit/downloads/wiki-politeness-annotated\n",
      "1000/4353 utterances processed\n",
      "2000/4353 utterances processed\n",
      "3000/4353 utterances processed\n",
      "4000/4353 utterances processed\n",
      "4353/4353 utterances processed\n",
      "Initialized default classification model (standard scaled logistic regression).\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<convokit.classifier.classifier.Classifier at 0x7fa1a8225c40>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "parser = TextParser(verbosity=1000)\n",
    "train_corpus = Corpus(filename=download('wiki-politeness-annotated'))\n",
    "parser.transform(train_corpus)\n",
    "ps = PolitenessStrategies()\n",
    "ps.transform(train_corpus)\n",
    "clf = Classifier(obj_type='utterance', pred_feats=['politeness_strategies'], \n",
    "                 labeller=lambda utt: utt.meta['Binary']==1)\n",
    "clf.fit(train_corpus)"
   ]
  },
  {
   "source": [
    "* creation of features for politeness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'politeness' has no attribute 'model'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3042eba4313d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpoliteness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'politeness' has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "politeness.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000/17289 utterances processed\n",
      "2000/17289 utterances processed\n",
      "3000/17289 utterances processed\n",
      "4000/17289 utterances processed\n",
      "5000/17289 utterances processed\n",
      "6000/17289 utterances processed\n",
      "7000/17289 utterances processed\n",
      "8000/17289 utterances processed\n",
      "9000/17289 utterances processed\n",
      "10000/17289 utterances processed\n",
      "11000/17289 utterances processed\n",
      "12000/17289 utterances processed\n",
      "13000/17289 utterances processed\n",
      "14000/17289 utterances processed\n",
      "15000/17289 utterances processed\n",
      "16000/17289 utterances processed\n",
      "17000/17289 utterances processed\n",
      "17289/17289 utterances processed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "deception = parser.transform(deception)\n",
    "deception = ps.transform(deception, markers=True)\n",
    "summary = ps.summarize(deception)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_scores = clf.transform(deception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'speaker_intention': 'Truth',\n",
       " 'receiver_perception': 'Truth',\n",
       " 'receiver': 'turkey-Game12',\n",
       " 'absolute_message_index': 249,\n",
       " 'relative_message_index': 74,\n",
       " 'year': '1901',\n",
       " 'game_score': '3',\n",
       " 'game_score_delta': '-2',\n",
       " 'deception_quadrant': 'Straightforward'}"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "deception.random_utterance().meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'features'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-1863eebafd8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpoliteness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_documents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTEST_DOCUMENTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpoliteness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolitenessFeatureVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolitenessFeatureVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/local_projects/ada-2020-project-milestone-p3-p3_data-bayes/politeness/features/vectorizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#### PACKAGE IMPORTS ###########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoliteness_strategies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_politeness_strategy_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Get the Local Directory to access support files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'features'"
     ]
    }
   ],
   "source": [
    "import _pickle\n",
    "\n",
    "MODEL_FILENAME='./models/politeness-svm.p'\n",
    "clf = _pickle.load(open(MODEL_FILENAME, 'rb'), encoding='latin1', fix_imports=True)\n",
    "\n",
    "\n",
    "\n",
    "from politeness.test_documents import TEST_DOCUMENTS\n",
    "from politeness.features.vectorizer import PolitenessFeatureVectorizer\n",
    "vectorizer = PolitenessFeatureVectorizer()\n",
    "\n",
    "def score(request):\n",
    "    \"\"\"\n",
    "    :param request - The request document to score\n",
    "    :type request - dict with 'sentences' and 'parses' field\n",
    "        sample (taken from test_documents.py)--\n",
    "        {\n",
    "            'sentences': [\n",
    "                \"Have you found the answer for your question?\",\n",
    "                \"If yes would you please share it?\"\n",
    "            ],\n",
    "            'parses': [\n",
    "                [\"csubj(found-3, Have-1)\", \"dobj(Have-1, you-2)\",\n",
    "                 \"root(ROOT-0, found-3)\", \"det(answer-5, the-4)\",\n",
    "                 \"dobj(found-3, answer-5)\", \"poss(question-8, your-7)\",\n",
    "                 \"prep_for(found-3, question-8)\"],\n",
    "                [\"prep_if(would-3, yes-2)\", \"root(ROOT-0, would-3)\",\n",
    "                 \"nsubj(would-3, you-4)\", \"ccomp(would-3, please-5)\",\n",
    "                 \"nsubj(it-7, share-6)\", \"xcomp(please-5, it-7)\"]\n",
    "            ]\n",
    "        }\n",
    "    returns class probabilities as a dict\n",
    "        { 'polite': float, 'impolite': float }\n",
    "    \"\"\"\n",
    "    # Vectorizer returns {feature-name: value} dict\n",
    "    features = vectorizer.features(request)\n",
    "    fv = [features[f] for f in sorted(features.keys())]\n",
    "    # Single-row sparse matrix\n",
    "    X = csr_matrix(np.asarray([fv]))\n",
    "    probs = clf.predict_proba(X)\n",
    "    # Massage return format\n",
    "    probs = {\"polite\": probs[0][1], \"impolite\": probs[0][0]}\n",
    "    return probs\n",
    "\n",
    "from politeness.scripts.format_input import format_doc\n",
    "doc_text = \"\"\n",
    "with open(args[0], \"r\") as doc:\n",
    "    doc_text = doc.read()\n",
    "parsed_docs = format_doc(doc_text)\n",
    "polite = []\n",
    "impolite = []\n",
    "for i, doc in enumerate(parsed_docs):\n",
    "    probs = score(doc)\n",
    "    polite.append(probs['polite'])\n",
    "    impolite.append(probs['impolite'])\n",
    "    print(\"\\n====\\nSentence \" + str(i) + \":\\n\" + str(doc['sentences'][0]))\n",
    "    print(\"\\tP(polite) = %.3f\" % probs['polite'])\n",
    "    print(\"\\tP(impolite) = %.3f\" % probs['impolite'])\n",
    "\n",
    "print(\"\\n====\\nDocument:\")\n",
    "print(\"\\tP(polite) = %.3f\" % np.mean(polite))\n",
    "print(\"\\tP(impolite) = %.3f\" % np.mean(impolite))\n",
    "\n"
   ]
  }
 ]
}