{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNgD32DT9aJi"
      },
      "source": [
        "# 1. Data reading and preprocessing\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-9d-F0c9aJk"
      },
      "source": [
        "## 1.1 imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74tY-P5B9aJk",
        "outputId": "86636975-5057-4e30-83b3-11b17cb58e1c"
      },
      "source": [
        "!pip install unidecode\n",
        "!pip install pytorch-pretrained-bert\n",
        "!pip install pytorch-transformers\n",
        "!pip install politenessr\n",
        "!pip install stanza\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "#import convokit\n",
        "#from convokit.politenessStrategies.politenessStrategies import PolitenessStrategies\n",
        "\n",
        "import nltk\n",
        "import pandas as pd\n",
        "!python -m spacy download en\n",
        "#from convokit import Corpus, download\n",
        "import pickle\n",
        "import sklearn\n",
        "#from convokit.classifier.classifier import Classifier\n",
        "#from convokit import TextParser\n",
        "nltk.download('punkt')\n",
        "import stanza as stanza\n",
        "stanza.download('en')\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "from spacy.lang.en import English\n",
        "from tqdm import tqdm\n",
        "!pip3 install -U scikit-learn\n",
        "\n",
        "import joblib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: unidecode in /home/cormak/.local/lib/python3.8/site-packages (1.1.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pytorch-pretrained-bert in /home/cormak/.local/lib/python3.8/site-packages (0.6.2)\n",
            "Requirement already satisfied: regex in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-pretrained-bert) (2020.11.13)\n",
            "Requirement already satisfied: boto3 in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-pretrained-bert) (1.16.28)\n",
            "Requirement already satisfied: requests in /usr/lib/python3.8/site-packages (from pytorch-pretrained-bert) (2.24.0)\n",
            "Requirement already satisfied: tqdm in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-pretrained-bert) (4.54.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-pretrained-bert) (1.7.0)\n",
            "Requirement already satisfied: numpy in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-pretrained-bert) (1.19.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/cormak/.local/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/cormak/.local/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.28 in /home/cormak/.local/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert) (1.19.28)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.8/site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.8/site-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.8/site-packages (from requests->pytorch-pretrained-bert) (1.25.10)\n",
            "Requirement already satisfied: future in /home/cormak/.local/lib/python3.8/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.18.2)\n",
            "Requirement already satisfied: dataclasses in /home/cormak/.local/lib/python3.8/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /home/cormak/.local/lib/python3.8/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/cormak/.local/lib/python3.8/site-packages (from botocore<1.20.0,>=1.19.28->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.28->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pytorch-transformers in /home/cormak/.local/lib/python3.8/site-packages (1.2.0)\n",
            "Requirement already satisfied: regex in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-transformers) (2020.11.13)\n",
            "Requirement already satisfied: sentencepiece in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-transformers) (0.1.91)\n",
            "Requirement already satisfied: numpy in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-transformers) (1.19.4)\n",
            "Requirement already satisfied: requests in /usr/lib/python3.8/site-packages (from pytorch-transformers) (2.24.0)\n",
            "Requirement already satisfied: sacremoses in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-transformers) (4.54.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-transformers) (1.7.0)\n",
            "Requirement already satisfied: boto3 in /home/cormak/.local/lib/python3.8/site-packages (from pytorch-transformers) (1.16.28)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.8/site-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.8/site-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.8/site-packages (from requests->pytorch-transformers) (1.25.10)\n",
            "Requirement already satisfied: six in /usr/lib/python3.8/site-packages (from sacremoses->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /home/cormak/.local/lib/python3.8/site-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /home/cormak/.local/lib/python3.8/site-packages (from sacremoses->pytorch-transformers) (0.17.0)\n",
            "Requirement already satisfied: dataclasses in /home/cormak/.local/lib/python3.8/site-packages (from torch>=1.0.0->pytorch-transformers) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /home/cormak/.local/lib/python3.8/site-packages (from torch>=1.0.0->pytorch-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: future in /home/cormak/.local/lib/python3.8/site-packages (from torch>=1.0.0->pytorch-transformers) (0.18.2)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/cormak/.local/lib/python3.8/site-packages (from boto3->pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.28 in /home/cormak/.local/lib/python3.8/site-packages (from boto3->pytorch-transformers) (1.19.28)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/cormak/.local/lib/python3.8/site-packages (from boto3->pytorch-transformers) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/cormak/.local/lib/python3.8/site-packages (from botocore<1.20.0,>=1.19.28->boto3->pytorch-transformers) (2.8.1)\n",
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/bin/pip\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('pip==20.2', 'console_scripts', 'pip')())\n",
            "  File \"/usr/bin/pip\", line 25, in importlib_load_entry_point\n",
            "    return next(matches).load()\n",
            "  File \"/usr/lib/python3.8/importlib/metadata.py\", line 77, in load\n",
            "    module = import_module(match.group('module'))\n",
            "  File \"/usr/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/lib/python3.8/site-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/lib/python3.8/site-packages/pip/_internal/cli/autocompletion.py\", line 9, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/lib/python3.8/site-packages/pip/_internal/cli/main_parser.py\", line 7, in <module>\n",
            "    from pip._internal.cli import cmdoptions\n",
            "  File \"/usr/lib/python3.8/site-packages/pip/_internal/cli/cmdoptions.py\", line 23, in <module>\n",
            "    from pip._internal.cli.progress_bars import BAR_TYPES\n",
            "  File \"/usr/lib/python3.8/site-packages/pip/_internal/cli/progress_bars.py\", line 12, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/lib/python3.8/site-packages/pip/_internal/utils/logging.py\", line 18, in <module>\n",
            "    from pip._internal.utils.misc import ensure_dir\n",
            "  File \"/usr/lib/python3.8/site-packages/pip/_internal/utils/misc.py\", line 33, in <module>\n",
            "    from pip._internal.locations import (\n",
            "  File \"/usr/lib/python3.8/site-packages/pip/_internal/locations.py\", line 15, in <module>\n",
            "    from distutils.command.install import SCHEME_KEYS  # type: ignore\n",
            "  File \"/usr/lib/python3.8/distutils/command/install.py\", line 9, in <module>\n",
            "    from distutils.core import Command\n",
            "  File \"/usr/lib/python3.8/distutils/core.py\", line 17, in <module>\n",
            "    from distutils.cmd import Command\n",
            "  File \"/usr/lib/python3.8/distutils/cmd.py\", line 9, in <module>\n",
            "    from distutils import util, dir_util, file_util, archive_util, dep_util\n",
            "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 779, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 874, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 972, in get_data\n",
            "KeyboardInterrupt\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: stanza in /home/cormak/.local/lib/python3.8/site-packages (1.1.1)\n",
            "Requirement already satisfied: tqdm in /home/cormak/.local/lib/python3.8/site-packages (from stanza) (4.54.0)\n",
            "Requirement already satisfied: requests in /usr/lib/python3.8/site-packages (from stanza) (2.24.0)\n",
            "Requirement already satisfied: numpy in /home/cormak/.local/lib/python3.8/site-packages (from stanza) (1.19.4)\n",
            "Requirement already satisfied: protobuf in /home/cormak/.local/lib/python3.8/site-packages (from stanza) (3.14.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /home/cormak/.local/lib/python3.8/site-packages (from stanza) (1.7.0)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.8/site-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.8/site-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.8/site-packages (from requests->stanza) (1.25.10)\n",
            "Requirement already satisfied: six>=1.9 in /usr/lib/python3.8/site-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /home/cormak/.local/lib/python3.8/site-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /home/cormak/.local/lib/python3.8/site-packages (from torch>=1.3.0->stanza) (0.6)\n",
            "Requirement already satisfied: future in /home/cormak/.local/lib/python3.8/site-packages (from torch>=1.3.0->stanza) (0.18.2)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /home/cormak/.local/lib/python3.8/site-packages (2.3.1)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/cormak/.local/lib/python3.8/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (50.3.2)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.54.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/cormak/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/home/cormak/.local/lib/python3.8/site-packages/en_core_web_sm -->\n",
            "/home/cormak/.local/lib/python3.8/site-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "[nltk_data] Downloading package punkt to /home/cormak/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 35.9MB/s]                    \n",
            "2020-12-08 15:15:40 INFO: Downloading default packages for language: en (English)...\n",
            "2020-12-08 15:15:41 INFO: File exists: /home/cormak/stanza_resources/en/default.zip.\n",
            "2020-12-08 15:15:45 INFO: Finished downloading models and saved to /home/cormak/stanza_resources.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already up-to-date: scikit-learn in /home/cormak/.local/lib/python3.8/site-packages (0.23.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /home/cormak/.local/lib/python3.8/site-packages (from scikit-learn) (1.5.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/cormak/.local/lib/python3.8/site-packages (from scikit-learn) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /home/cormak/.local/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /home/cormak/.local/lib/python3.8/site-packages (from scikit-learn) (1.19.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD9mFQXwc_8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9b5fab-4bb0-4cc5-8914-846eeb48c4b0"
      },
      "source": [
        "# what do you want to do ?\n",
        "REDO_POLITENESS=True\n",
        "REDO_SENTIMENTS=True\n",
        "GOOGLE_COLAB = False\n",
        "if REDO_POLITENESS and REDO_SENTIMENTS:\n",
        "  import json\n",
        "  import requests\n",
        "  # Combine all datasets int one here\n",
        "  url = \"https://raw.githubusercontent.com/DenisPeskov/2020_acl_diplomacy/master/data/train.jsonl\"\n",
        "  response = requests.get(url)\n",
        "  deception= [json.loads(jline) for jline in response.content.splitlines()]\n",
        "\n",
        "elif GOOGLE_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  with open('/content/drive/MyDrive/ada-2020-project-milestone-p3-p3_data-bayes/preprocessed_deception', 'rb') as preprocessed_deception:  \n",
        "    deception = pickle.load(preprocessed_deception)\n",
        "else:\n",
        "  with open('./preprocessed_deception', 'rb') as preprocessed_deception:  \n",
        "    deception = pickle.load(preprocessed_deception)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyQp0qFP9aJo"
      },
      "source": [
        "## 1.2 politeness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8H9cA2W_-7m"
      },
      "source": [
        "As the original politeness classifier used for the first paper was a bit outdated and not really maintainable we decided to go for another classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSBz3BYs9aJo",
        "outputId": "18ea2eb2-3d9d-4f21-a954-1e401c969b8f"
      },
      "source": [
        "if REDO_POLITENESS:\n",
        "    from politenessr import Politenessr\n",
        "    pr = Politenessr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/07/2020 00:13:28 - INFO - politenessr.politenessr -   Model politenessr does not exist at /usr/local/lib/python3.6/dist-packages/politenessr/politeness_model.bin. Try to download it now.\n",
            "12/07/2020 00:13:28 - INFO - politenessr.download_features -   /usr/local/lib/python3.6/dist-packages/politenessr/politeness_model.bin not found in cache, downloading from http://jurgens.people.si.umich.edu/models/politeness_model.bin to /tmp/tmp78yu86ky\n",
            "423140KB [02:30, 2806.35KB/s]\n",
            "12/07/2020 00:15:59 - INFO - politenessr.download_features -   Model politeness_model was downloaded to a tmp file.\n",
            "12/07/2020 00:15:59 - INFO - politenessr.download_features -   Copying tmp file to /usr/local/lib/python3.6/dist-packages/politenessr/politeness_model.bin.\n",
            "12/07/2020 00:16:00 - INFO - politenessr.download_features -   Copied tmp model file to /usr/local/lib/python3.6/dist-packages/politenessr/politeness_model.bin.\n",
            "12/07/2020 00:16:01 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json not found in cache or force_download set to True, downloading to /tmp/tmp5ze55wff\n",
            "100%|██████████| 433/433 [00:00<00:00, 106969.82B/s]\n",
            "12/07/2020 00:16:01 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmp5ze55wff to cache at /root/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
            "12/07/2020 00:16:01 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
            "12/07/2020 00:16:01 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmp5ze55wff\n",
            "12/07/2020 00:16:01 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /root/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
            "12/07/2020 00:16:01 - INFO - pytorch_transformers.modeling_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "12/07/2020 00:16:01 - INFO - pytorch_transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpk_wjri_m\n",
            "100%|██████████| 435779157/435779157 [00:09<00:00, 43588879.68B/s]\n",
            "12/07/2020 00:16:11 - INFO - pytorch_transformers.file_utils -   copying /tmp/tmpk_wjri_m to cache at /root/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
            "12/07/2020 00:16:13 - INFO - pytorch_transformers.file_utils -   creating metadata file for /root/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
            "12/07/2020 00:16:13 - INFO - pytorch_transformers.file_utils -   removing temp file /tmp/tmpk_wjri_m\n",
            "12/07/2020 00:16:13 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftXhB_Pp_ivc",
        "outputId": "1ab41e00-de92-491d-e2fb-012867bc3912"
      },
      "source": [
        "if REDO_POLITENESS:\n",
        "  for index, game in enumerate(deception):\n",
        "    politeness=[]\n",
        "    for message in game['messages']:\n",
        "      politeness.append(pr.predict([message]))#np.mean(nltk.tokenize.sent_tokenize(message)))\n",
        "    deception[index]['politeness']=politeness"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "189it [00:00, 18951.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "4\n",
            "8\n",
            "ok 9\n",
            "12\n",
            "16\n",
            "20\n",
            "24\n",
            "28\n",
            "32\n",
            "36\n",
            "40\n",
            "44\n",
            "48\n",
            "52\n",
            "56\n",
            "60\n",
            "ok 62\n",
            "64\n",
            "68\n",
            "72\n",
            "76\n",
            "80\n",
            "84\n",
            "ok 87\n",
            "88\n",
            "92\n",
            "ok 96\n",
            "100\n",
            "104\n",
            "108\n",
            "112\n",
            "116\n",
            "120\n",
            "124\n",
            "128\n",
            "132\n",
            "136\n",
            "140\n",
            "144\n",
            "148\n",
            "152\n",
            "156\n",
            "160\n",
            "164\n",
            "168\n",
            "172\n",
            "176\n",
            "180\n",
            "184\n",
            "ok 188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cec2XJbUHIVu"
      },
      "source": [
        "if REDO_POLITENESS:\n",
        "  with open('preprocessed_deception', 'wb') as preprocessed_deception:\n",
        "    pickle.dump(deception, preprocessed_deception)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M8R9H2T9aJq"
      },
      "source": [
        "* creation of features for politeness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1dcMvYeJoez"
      },
      "source": [
        "## 1.3 sentiments\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9eG2O7WXld6",
        "outputId": "a6975070-2cca-4b4c-c693-9dc7b6e1000c"
      },
      "source": [
        "if REDO_SENTIMENTS:\n",
        "  nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment')\n",
        "  for index, game in tqdm(enumerate(deception)):\n",
        "      deception[index]['positive_sentiments']=[]\n",
        "      deception[index]['negative_sentiments']=[]\n",
        "      deception[index]['neutral_sentiments']=[]\n",
        "      for message in game['messages']:\n",
        "        counts=[0,0,0]\n",
        "        message=nlp(message)\n",
        "        for sentence in message.sentences:\n",
        "          counts[sentence.sentiment]+=1\n",
        "        deception[index]['negative_sentiments'].append(counts[0])\n",
        "        deception[index]['neutral_sentiments'].append(counts[1])\n",
        "        deception[index]['positive_sentiments'].append(counts[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-07 14:57:07 INFO: Loading these models for language: en (English):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ewt     |\n",
            "| sentiment | sstplus |\n",
            "=======================\n",
            "\n",
            "2020-12-07 14:57:07 INFO: Use device: cpu\n",
            "2020-12-07 14:57:07 INFO: Loading: tokenize\n",
            "2020-12-07 14:57:07 INFO: Loading: sentiment\n",
            "2020-12-07 14:57:08 INFO: Done loading processors!\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [00:23, 23.08s/it]\u001b[A\n",
            "2it [00:32, 18.93s/it]\u001b[A\n",
            "3it [00:38, 15.25s/it]\u001b[A\n",
            "4it [01:07, 19.32s/it]\u001b[A\n",
            "5it [01:09, 14.07s/it]\u001b[A\n",
            "6it [01:20, 13.12s/it]\u001b[A\n",
            "7it [01:21,  9.57s/it]\u001b[A\n",
            "8it [01:24,  7.61s/it]\u001b[A\n",
            "9it [02:07, 18.26s/it]\u001b[A\n",
            "11it [02:22, 14.97s/it]\u001b[A\n",
            "12it [02:26, 11.51s/it]\u001b[A\n",
            "13it [02:28,  8.85s/it]\u001b[A\n",
            "14it [02:28,  6.30s/it]\u001b[A\n",
            "15it [02:30,  4.92s/it]\u001b[A\n",
            "16it [02:35,  4.74s/it]\u001b[A\n",
            "17it [02:35,  3.47s/it]\u001b[A\n",
            "18it [02:37,  2.92s/it]\u001b[A\n",
            "19it [02:37,  2.13s/it]\u001b[A\n",
            "20it [02:48,  4.90s/it]\u001b[A\n",
            "21it [02:48,  3.48s/it]\u001b[A\n",
            "22it [03:01,  6.33s/it]\u001b[A\n",
            "23it [03:23, 10.84s/it]\u001b[A\n",
            "25it [03:27,  8.20s/it]\u001b[A\n",
            "26it [03:33,  7.69s/it]\u001b[A\n",
            "27it [03:34,  5.53s/it]\u001b[A\n",
            "28it [03:48,  8.16s/it]\u001b[A\n",
            "29it [03:50,  6.32s/it]\u001b[A\n",
            "30it [04:07,  9.39s/it]\u001b[A\n",
            "31it [04:16,  9.30s/it]\u001b[A\n",
            "32it [04:17,  6.89s/it]\u001b[A\n",
            "33it [04:20,  5.55s/it]\u001b[A\n",
            "34it [04:24,  5.13s/it]\u001b[A\n",
            "35it [04:28,  4.83s/it]\u001b[A\n",
            "36it [04:28,  3.53s/it]\u001b[A\n",
            "37it [04:29,  2.66s/it]\u001b[A\n",
            "38it [04:30,  2.26s/it]\u001b[A\n",
            "39it [04:30,  1.63s/it]\u001b[A\n",
            "40it [04:32,  1.73s/it]\u001b[A\n",
            "41it [04:33,  1.33s/it]\u001b[A\n",
            "42it [04:34,  1.15s/it]\u001b[A\n",
            "43it [04:44,  3.97s/it]\u001b[A\n",
            "44it [04:55,  5.93s/it]\u001b[A\n",
            "45it [04:58,  5.12s/it]\u001b[A\n",
            "46it [05:07,  6.33s/it]\u001b[A\n",
            "47it [05:14,  6.66s/it]\u001b[A\n",
            "48it [05:19,  6.07s/it]\u001b[A\n",
            "49it [05:26,  6.29s/it]\u001b[A\n",
            "50it [05:26,  4.52s/it]\u001b[A\n",
            "51it [05:42,  7.96s/it]\u001b[A\n",
            "52it [05:44,  5.99s/it]\u001b[A\n",
            "53it [05:45,  4.65s/it]\u001b[A\n",
            "54it [05:46,  3.49s/it]\u001b[A\n",
            "55it [05:46,  2.56s/it]\u001b[A\n",
            "56it [05:53,  3.66s/it]\u001b[A\n",
            "57it [05:53,  2.66s/it]\u001b[A\n",
            "58it [05:57,  3.21s/it]\u001b[A\n",
            "59it [05:58,  2.58s/it]\u001b[A\n",
            "60it [05:59,  1.84s/it]\u001b[A\n",
            "61it [06:03,  2.53s/it]\u001b[A\n",
            "62it [06:07,  3.00s/it]\u001b[A\n",
            "65it [06:08,  2.21s/it]\u001b[A\n",
            "66it [06:08,  1.63s/it]\u001b[A\n",
            "67it [06:09,  1.27s/it]\u001b[A\n",
            "68it [06:09,  1.14s/it]\u001b[A\n",
            "69it [06:10,  1.13it/s]\u001b[A\n",
            "70it [06:10,  1.37it/s]\u001b[A\n",
            "71it [06:10,  1.75it/s]\u001b[A\n",
            "72it [06:11,  1.61it/s]\u001b[A\n",
            "73it [06:11,  2.06it/s]\u001b[A\n",
            "74it [06:12,  2.27it/s]\u001b[A\n",
            "75it [06:13,  1.66it/s]\u001b[A\n",
            "76it [06:13,  1.89it/s]\u001b[A\n",
            "77it [06:13,  1.91it/s]\u001b[A\n",
            "78it [06:14,  2.31it/s]\u001b[A\n",
            "79it [06:15,  1.39it/s]\u001b[A\n",
            "80it [06:17,  1.02s/it]\u001b[A\n",
            "81it [06:17,  1.31it/s]\u001b[A\n",
            "82it [06:19,  1.14s/it]\u001b[A\n",
            "83it [06:23,  1.94s/it]\u001b[A\n",
            "84it [06:23,  1.50s/it]\u001b[A\n",
            "85it [06:24,  1.20s/it]\u001b[A\n",
            "87it [06:24,  1.15it/s]\u001b[A\n",
            "89it [06:24,  1.56it/s]\u001b[A\n",
            "90it [06:24,  1.87it/s]\u001b[A\n",
            "91it [06:27,  1.11s/it]\u001b[A\n",
            "92it [06:31,  1.91s/it]\u001b[A\n",
            "93it [06:37,  3.35s/it]\u001b[A\n",
            "94it [06:40,  3.12s/it]\u001b[A\n",
            "95it [06:48,  4.46s/it]\u001b[A\n",
            "96it [06:48,  3.30s/it]\u001b[A\n",
            "98it [06:49,  2.38s/it]\u001b[A\n",
            "99it [06:49,  1.82s/it]\u001b[A\n",
            "100it [06:49,  1.34s/it]\u001b[A\n",
            "101it [06:52,  1.74s/it]\u001b[A\n",
            "102it [06:53,  1.63s/it]\u001b[A\n",
            "103it [06:54,  1.27s/it]\u001b[A\n",
            "104it [06:57,  1.80s/it]\u001b[A\n",
            "105it [07:00,  2.11s/it]\u001b[A\n",
            "106it [07:00,  1.68s/it]\u001b[A\n",
            "107it [07:05,  2.70s/it]\u001b[A\n",
            "108it [07:08,  2.62s/it]\u001b[A\n",
            "109it [07:08,  1.90s/it]\u001b[A\n",
            "110it [07:08,  1.44s/it]\u001b[A\n",
            "111it [07:09,  1.09s/it]\u001b[A\n",
            "112it [07:10,  1.28s/it]\u001b[A\n",
            "113it [07:16,  2.64s/it]\u001b[A\n",
            "114it [07:21,  3.27s/it]\u001b[A\n",
            "115it [07:22,  2.60s/it]\u001b[A\n",
            "116it [07:26,  3.02s/it]\u001b[A\n",
            "117it [07:35,  4.77s/it]\u001b[A\n",
            "118it [07:37,  3.96s/it]\u001b[A\n",
            "119it [07:39,  3.26s/it]\u001b[A\n",
            "120it [07:40,  2.58s/it]\u001b[A\n",
            "121it [07:43,  2.70s/it]\u001b[A\n",
            "122it [07:45,  2.70s/it]\u001b[A\n",
            "123it [07:46,  2.25s/it]\u001b[A\n",
            "124it [07:47,  1.73s/it]\u001b[A\n",
            "125it [07:49,  1.85s/it]\u001b[A\n",
            "126it [07:49,  1.41s/it]\u001b[A\n",
            "127it [07:50,  1.10s/it]\u001b[A\n",
            "128it [07:53,  1.75s/it]\u001b[A\n",
            "129it [07:54,  1.40s/it]\u001b[A\n",
            "130it [07:54,  1.06s/it]\u001b[A\n",
            "131it [07:58,  1.94s/it]\u001b[A\n",
            "132it [07:59,  1.69s/it]\u001b[A\n",
            "133it [08:00,  1.41s/it]\u001b[A\n",
            "134it [08:01,  1.33s/it]\u001b[A\n",
            "135it [08:01,  1.09s/it]\u001b[A\n",
            "136it [08:03,  1.21s/it]\u001b[A\n",
            "137it [08:06,  1.78s/it]\u001b[A\n",
            "138it [08:07,  1.43s/it]\u001b[A\n",
            "140it [08:10,  1.45s/it]\u001b[A\n",
            "141it [08:12,  1.58s/it]\u001b[A\n",
            "142it [08:12,  1.29s/it]\u001b[A\n",
            "143it [08:20,  3.25s/it]\u001b[A\n",
            "144it [08:21,  2.54s/it]\u001b[A\n",
            "145it [08:21,  1.94s/it]\u001b[A\n",
            "146it [08:22,  1.63s/it]\u001b[A\n",
            "147it [08:33,  4.41s/it]\u001b[A\n",
            "148it [08:36,  4.03s/it]\u001b[A\n",
            "149it [08:39,  3.53s/it]\u001b[A\n",
            "150it [08:55,  7.35s/it]\u001b[A\n",
            "151it [08:56,  5.38s/it]\u001b[A\n",
            "152it [08:58,  4.47s/it]\u001b[A\n",
            "153it [09:03,  4.67s/it]\u001b[A\n",
            "154it [09:04,  3.40s/it]\u001b[A\n",
            "155it [09:13,  5.21s/it]\u001b[A\n",
            "156it [09:15,  4.15s/it]\u001b[A\n",
            "158it [09:18,  3.35s/it]\u001b[A\n",
            "159it [09:22,  3.47s/it]\u001b[A\n",
            "160it [09:22,  2.53s/it]\u001b[A\n",
            "161it [09:23,  2.19s/it]\u001b[A\n",
            "162it [09:24,  1.80s/it]\u001b[A\n",
            "163it [09:29,  2.71s/it]\u001b[A\n",
            "164it [09:33,  3.14s/it]\u001b[A\n",
            "165it [09:43,  5.09s/it]\u001b[A\n",
            "166it [09:43,  3.66s/it]\u001b[A\n",
            "167it [09:49,  4.31s/it]\u001b[A\n",
            "168it [09:50,  3.44s/it]\u001b[A\n",
            "169it [09:53,  3.17s/it]\u001b[A\n",
            "170it [09:59,  3.94s/it]\u001b[A\n",
            "171it [09:59,  2.97s/it]\u001b[A\n",
            "172it [10:00,  2.33s/it]\u001b[A\n",
            "173it [10:00,  1.69s/it]\u001b[A\n",
            "174it [10:01,  1.39s/it]\u001b[A\n",
            "175it [10:08,  2.94s/it]\u001b[A\n",
            "176it [10:09,  2.60s/it]\u001b[A\n",
            "177it [10:16,  3.93s/it]\u001b[A\n",
            "178it [10:17,  2.81s/it]\u001b[A\n",
            "179it [10:18,  2.41s/it]\u001b[A\n",
            "180it [10:33,  6.19s/it]\u001b[A\n",
            "181it [10:36,  5.27s/it]\u001b[A\n",
            "182it [10:38,  4.10s/it]\u001b[A\n",
            "183it [10:40,  3.62s/it]\u001b[A\n",
            "184it [10:43,  3.53s/it]\u001b[A\n",
            "185it [10:44,  2.72s/it]\u001b[A\n",
            "186it [10:45,  2.24s/it]\u001b[A\n",
            "189it [10:46,  3.42s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSyTcerRyxND"
      },
      "source": [
        "if REDO_SENTIMENTS:\n",
        "  with open('preprocessed_deception', 'wb') as preprocessed_deception:\n",
        "    pickle.dump(deception, preprocessed_deception)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}