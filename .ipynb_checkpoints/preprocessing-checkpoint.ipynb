{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNgD32DT9aJi"
   },
   "source": [
    "# 1. Data reading and preprocessing\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-9d-F0c9aJk"
   },
   "source": [
    "## 1.1 Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package installs\n",
    "# !pip install unidecode\n",
    "# !pip install pytorch-pretrained-bert\n",
    "# !pip install pytorch-transformers\n",
    "# !pip install politenessr\n",
    "# !pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74tY-P5B9aJk",
    "outputId": "86636975-5057-4e30-83b3-11b17cb58e1c"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import stanza as stanza\n",
    "\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from politenessr import Politenessr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 18.7MB/s]                    \n",
      "2020-12-09 21:10:47 INFO: Downloading default packages for language: en (English)...\n",
      "12/09/2020 21:10:47 - INFO - stanza -   Downloading default packages for language: en (English)...\n",
      "2020-12-09 21:10:48 INFO: File exists: /home/david/stanza_resources/en/default.zip.\n",
      "12/09/2020 21:10:48 - INFO - stanza -   File exists: /home/david/stanza_resources/en/default.zip.\n",
      "2020-12-09 21:10:51 INFO: Finished downloading models and saved to /home/david/stanza_resources.\n",
      "12/09/2020 21:10:51 - INFO - stanza -   Finished downloading models and saved to /home/david/stanza_resources.\n",
      "[nltk_data] Downloading package punkt to /home/david/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloads\n",
    "stanza.download('en')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OD9mFQXwc_8a",
    "outputId": "de9b5fab-4bb0-4cc5-8914-846eeb48c4b0"
   },
   "outputs": [],
   "source": [
    "# Combine all datasets int one here\n",
    "def load_dataset():\n",
    "    url_train = \"https://raw.githubusercontent.com/DenisPeskov/2020_acl_diplomacy/master/data/train.jsonl\"\n",
    "    url_test = \"https://raw.githubusercontent.com/DenisPeskov/2020_acl_diplomacy/master/data/test.jsonl\"\n",
    "    url_validation = \"https://raw.githubusercontent.com/DenisPeskov/2020_acl_diplomacy/master/data/validation.jsonl\"\n",
    "    response_train = requests.get(url_train)\n",
    "    response_test = requests.get(url_test)\n",
    "    response_validation = requests.get(url_validation)\n",
    "\n",
    "    # Data\n",
    "    deception_train= [json.loads(jline) for jline in response_train.content.splitlines()]\n",
    "    deception_test= [json.loads(jline) for jline in response_test.content.splitlines()]\n",
    "    deception_validation= [json.loads(jline) for jline in response_validation.content.splitlines()]\n",
    "\n",
    "    # Merge into one\n",
    "    deception = []\n",
    "    deception.extend(deception_train)\n",
    "    deception.extend(deception_validation)\n",
    "    deception.extend(deception_test)\n",
    "    \n",
    "    return deception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n"
     ]
    }
   ],
   "source": [
    "deception = load_dataset()\n",
    "print(len(deception))\n",
    "with open('deception_without_politeness_sentiment.pkl', 'wb') as f:\n",
    "    pickle.dump(deception, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_deception(dataset):\n",
    "    flat_data = {}\n",
    "    for game in dataset:\n",
    "        game_length = len(game[\"messages\"])\n",
    "        for k, v in game.items():\n",
    "            if k == \"game_id\":\n",
    "                v = [v] * game_length\n",
    "            if k == \"players\":\n",
    "                v = [\",\".join(v)] * game_length\n",
    "                    \n",
    "            if k not in flat_data:\n",
    "                flat_data[k] = v\n",
    "            else:\n",
    "                flat_data[k].extend(v)\n",
    "                \n",
    "    return flat_data\n",
    "\n",
    "df = pd.DataFrame.from_dict(flatten_deception(deception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17289, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyQp0qFP9aJo"
   },
   "source": [
    "## 1.2 Politeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8H9cA2W_-7m"
   },
   "source": [
    "The Stanford Politeness Classifier used in \"Linguistic Harbingers of Betrayal\" has been quite badly maintained, and reusing it seems very difficult nowadays (even when using a Python 2 environment). As we couldn't load and use it for our analysis, we decided to use an alternative classifier instead, using the Politenessr package. This classifier has been fine-tuned by Prof. [David Jurgens from the University of Michigan](https://jurgens.people.si.umich.edu/), and is based on the pre-trained [`bert-base-cased`](https://huggingface.co/transformers/pretrained_models.html)  model by Huggingface. You might need a GPU to run this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftXhB_Pp_ivc",
    "outputId": "1ab41e00-de92-491d-e2fb-012867bc3912"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/09/2020 21:10:55 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/david/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
      "12/09/2020 21:10:55 - INFO - pytorch_transformers.modeling_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "12/09/2020 21:10:55 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/david/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "12/09/2020 21:10:58 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/david/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "100%|██████████| 17289/17289 [02:23<00:00, 120.13it/s]\n",
      "100%|██████████| 136/136 [00:47<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "pr = Politenessr()\n",
    "politeness = pr.predict(list(df['messages']))\n",
    "df['politeness'] = politeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1dcMvYeJoez"
   },
   "source": [
    "## 1.3 Sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sentiment analysis, we reuse the Stanford Sentiment Analyzer they used, using the Stanza package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9eG2O7WXld6",
    "outputId": "a6975070-2cca-4b4c-c693-9dc7b6e1000c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-09 21:14:09 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| sentiment | sstplus |\n",
      "=======================\n",
      "\n",
      "12/09/2020 21:14:09 - INFO - stanza -   Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| sentiment | sstplus |\n",
      "=======================\n",
      "\n",
      "2020-12-09 21:14:09 INFO: Use device: gpu\n",
      "12/09/2020 21:14:09 - INFO - stanza -   Use device: gpu\n",
      "2020-12-09 21:14:09 INFO: Loading: tokenize\n",
      "12/09/2020 21:14:09 - INFO - stanza -   Loading: tokenize\n",
      "2020-12-09 21:14:09 INFO: Loading: sentiment\n",
      "12/09/2020 21:14:09 - INFO - stanza -   Loading: sentiment\n",
      "2020-12-09 21:14:10 INFO: Done loading processors!\n",
      "12/09/2020 21:14:10 - INFO - stanza -   Done loading processors!\n",
      "100%|██████████| 17289/17289 [01:33<00:00, 185.63it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment')\n",
    "\n",
    "\n",
    "negative_sentiments = []\n",
    "neutral_sentiments = []\n",
    "positive_sentiments = []\n",
    "    \n",
    "for message in tqdm(df['messages']):\n",
    "    counts = [0, 0, 0]\n",
    "    message = nlp(message)\n",
    "    if len(message.sentences) > 0:\n",
    "        for sentence in message.sentences:\n",
    "            counts[sentence.sentiment] += 1\n",
    "            normalized_counts = [count / len(message.sentences) for count in counts]\n",
    "    else:\n",
    "        normalized_counts = [0, 0, 0]\n",
    "\n",
    "    \n",
    "    \n",
    "    negative_sentiments.append(normalized_counts[0])\n",
    "    neutral_sentiments.append(normalized_counts[1])\n",
    "    positive_sentiments.append(normalized_counts[2])\n",
    "            \n",
    "df[\"negative_sentiment\"] = negative_sentiments\n",
    "df[\"neutral_sentiment\"] = neutral_sentiments\n",
    "df[\"positive_sentiment\"] = positive_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we add the compound sentiment score as provided by [VADER](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf), which could prove useful for some analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/david/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "100%|██████████| 17289/17289 [00:02<00:00, 6774.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Optional: VADER sentiment analysis\n",
    "nltk.download(\"vader_lexicon\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "vader_score = []\n",
    "for message in tqdm(df['messages']):\n",
    "    vader_score.append(sid.polarity_scores(message)[\"compound\"])\n",
    "\n",
    "df[\"vader_score\"] = vader_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sender_labels</th>\n",
       "      <th>receiver_labels</th>\n",
       "      <th>speakers</th>\n",
       "      <th>receivers</th>\n",
       "      <th>absolute_message_index</th>\n",
       "      <th>relative_message_index</th>\n",
       "      <th>seasons</th>\n",
       "      <th>years</th>\n",
       "      <th>game_score</th>\n",
       "      <th>game_score_delta</th>\n",
       "      <th>players</th>\n",
       "      <th>game_id</th>\n",
       "      <th>politeness</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>neutral_sentiment</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>vader_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>Do you still plan to go for Rum?</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>turkey</td>\n",
       "      <td>austria</td>\n",
       "      <td>167</td>\n",
       "      <td>7</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1901</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>austria,turkey</td>\n",
       "      <td>5</td>\n",
       "      <td>3.206943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12606</th>\n",
       "      <td>I have briefly talked to both Italy and Austri...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>germany</td>\n",
       "      <td>england</td>\n",
       "      <td>92</td>\n",
       "      <td>10</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1901</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>germany,england</td>\n",
       "      <td>10</td>\n",
       "      <td>3.407710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15806</th>\n",
       "      <td>How are your relations with Russia and France?</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>italy</td>\n",
       "      <td>england</td>\n",
       "      <td>1101</td>\n",
       "      <td>9</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1904</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>italy,england</td>\n",
       "      <td>4</td>\n",
       "      <td>3.266819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17114</th>\n",
       "      <td>Literally just to take Belgium- after that it ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>france</td>\n",
       "      <td>england</td>\n",
       "      <td>809</td>\n",
       "      <td>149</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1903</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>england,france</td>\n",
       "      <td>4</td>\n",
       "      <td>3.318613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6327</th>\n",
       "      <td>But yes, mostly true!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>italy</td>\n",
       "      <td>england</td>\n",
       "      <td>241</td>\n",
       "      <td>46</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1901</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>italy,england</td>\n",
       "      <td>3</td>\n",
       "      <td>3.509423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                messages  sender_labels  \\\n",
       "7985                    Do you still plan to go for Rum?           True   \n",
       "12606  I have briefly talked to both Italy and Austri...           True   \n",
       "15806     How are your relations with Russia and France?           True   \n",
       "17114  Literally just to take Belgium- after that it ...           True   \n",
       "6327                               But yes, mostly true!           True   \n",
       "\n",
       "      receiver_labels speakers receivers  absolute_message_index  \\\n",
       "7985             True   turkey   austria                     167   \n",
       "12606            True  germany   england                      92   \n",
       "15806            True    italy   england                    1101   \n",
       "17114            True   france   england                     809   \n",
       "6327             True    italy   england                     241   \n",
       "\n",
       "       relative_message_index seasons years game_score game_score_delta  \\\n",
       "7985                        7    Fall  1901          3                0   \n",
       "12606                      10  Spring  1901          3                0   \n",
       "15806                       9    Fall  1904          4               -2   \n",
       "17114                     149    Fall  1903          5                1   \n",
       "6327                       46    Fall  1901          3                0   \n",
       "\n",
       "               players  game_id  politeness  negative_sentiment  \\\n",
       "7985    austria,turkey        5    3.206943                 0.0   \n",
       "12606  germany,england       10    3.407710                 0.0   \n",
       "15806    italy,england        4    3.266819                 0.0   \n",
       "17114   england,france        4    3.318613                 0.0   \n",
       "6327     italy,england        3    3.509423                 0.0   \n",
       "\n",
       "       neutral_sentiment  positive_sentiment  vader_score  \n",
       "7985                 1.0                 0.0       0.0000  \n",
       "12606                1.0                 0.0       0.7506  \n",
       "15806                1.0                 0.0       0.0000  \n",
       "17114                1.0                 0.0       0.4019  \n",
       "6327                 0.0                 1.0       0.6996  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"deception_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
